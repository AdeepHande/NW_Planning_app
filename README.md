### AI Based Network Expansion Planning App
The directory structure of the repository is as follows:

--------



    â”œâ”€â”€ README.md          
    â”œâ”€â”€ data
    â”‚Â Â  â”œâ”€â”€ master.csv            <- Internal data comprising feasiblity requests from T1 and T2 cities.
    â”‚Â Â  â”œâ”€â”€ PoP Data              <- Point of presence (PoP) data
    |   |   |â”€â”€ Wireline_pop.csv  
    |   |   |â”€â”€ Wireless_pop.csv
    |   |   â””â”€â”€ handhole_pop.csv
    â”‚Â Â  â””â”€â”€ India_AC.shp          <- The shape files comprising all Assembly Constitutencies in India.
    â”‚
    â”œâ”€â”€ models                    <- Parent model for implementing MaxDiameter Clustering Algorithm. 
    â”‚   â””â”€â”€ DC_clustering.py
    |
    â”œâ”€â”€ notebooks                 <- Jupyter notebooks  
    â”œâ”€â”€ requirements.txt          <- The requirements file for reproducing the analysis environment.
    â”‚ 
    â”œâ”€â”€ src                       <- Source code for the app.
    â”‚Â Â  â”œâ”€â”€ __init__.py           <- Makes src a Python module
    â”‚   â”‚
    â”‚Â Â  â”œâ”€â”€ page1.py              <- Script to create Landing Page.  
    â”‚Â Â  â”œâ”€â”€ page2.py              <- Script for Duplicate Checker (In dev) 
    â”‚Â Â  â”œâ”€â”€ page3.py              <- Script for the clustering app. 
    |Â   â”œâ”€â”€ multipage.py          <- Script for the multipage (Docker Image built on the page)
    â”‚Â Â  â””â”€â”€ utils.py              <- Script for helper functions and utilities
    â”‚
    â”œâ”€â”€ streamlit
    |   â””â”€â”€ config.toml           <- configurations such as theme, fonts, etc.
    â””â”€â”€ Dockerfile                <- Dockerfile to build the Docker Image and run it.
    


--------

The app is structured as follows:
* Page 1: Landing Page
  
      User has to select among
            * Duplicate Checker (Page 2)
            * Uploading external data (Page 3)
            * Clustering App (Page 4)
* Page 2: Duplicate Checker (In dev)

      Input: dataframe df to remove duplicates (Coordinates are necessary)
      Output: Returns dataframe df after checking for duplicates.
* Page 3: Uploading external data 

      Input: 
            A) Dataframe df (from Duplicate Checker)
            B) Wireline Point of Presence ( Wireline PoP)
            C) Wireless Point of Presence (Wireless PoP)
            D) Handhole Point of Presence ( Handhole PoP)
      Default data: 
            * Internal data (Master data)
      
      Output:
            * Spatially Join (Master Data, df) ðŸ †  df_dash
* Page 4: Clustering App
      
      Input data:
            * df_dash 
            * Configurable Parameters (set by the user)
      Returns:
            * Output.zip
                  â”œâ”€â”€ Final_clustered_data.csv
                  â”œâ”€â”€ Merged_final_data.csv  (categorized clustered data)
                  â”œâ”€â”€ Bandwidth_potential_per_cluster.csv
                  â”œâ”€â”€ plots.html 
                  â””â”€â”€ plots.kml (In dev)

### Dev

1. Create an environment ```conda create -n streamlit-template python=3.8.5 pip```.

2. Install requirements: ```pip install -r app/requirements.txt```

#### Run the App
* ```cd app```
* ```streamlit run multipage.py```
